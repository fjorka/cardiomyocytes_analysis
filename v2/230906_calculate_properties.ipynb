{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nd2\n",
    "from tifffile import imread\n",
    "from skimage.io import imread as imread_png\n",
    "\n",
    "from skimage.measure import regionprops_table\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import circmean, circstd\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from cardiomyocytes_helper_functions import segment_actin_3D, calculate_perpendicular_index, get_internal_points, create_edge_visual,find_fibers_orientation_v2, orientations_from_vertices,interpolate_and_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir = r'D:\\data_analysis\\2022_Sahana\\OneDrive_1_20-06-2023\\Images_with_DAPI\\Masks'\n",
    "vertices_dir = mask_dir\n",
    "im_dir = r'C:\\Users\\lab\\OneDrive - University of Pittsburgh\\230516_reorder_Sahana\\Images'\n",
    "\n",
    "legend_path = r'D:\\data_analysis\\2022_Sahana\\scrambler.csv'\n",
    "\n",
    "save_path = r'D:\\data_analysis\\2022_Sahana\\OneDrive_1_20-06-2023\\Images_with_DAPI\\Results_recalculated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in legend how images were scrambled\n",
    "df_legend = pd.read_csv(legend_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(secret_n):\n",
    "\n",
    "    old_path = df_legend.loc[df_legend.num == secret_n,'old_path'].tolist()[0]\n",
    "\n",
    "    if 'Fibronectin' in old_path:\n",
    "        condition = 'Fibronectin'\n",
    "    else:\n",
    "        condition = 'Collagen'\n",
    "\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dapi(num):\n",
    "\n",
    "    im_path = os.path.join(im_dir,f'{str(num).zfill(2)}.nd2')\n",
    "    im = nd2.imread(im_path)\n",
    "\n",
    "    if im.shape[1]>2:\n",
    "        dapi = True\n",
    "    else:\n",
    "        dapi = False\n",
    "    \n",
    "    return dapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of channels in this set\n",
    "channel_names = ['actin','plak','DAPI']\n",
    "\n",
    "# general properties of cells to be calculated\n",
    "properties = ['label','area','centroid','bbox','eccentricity','orientation','intensity_image','image','intensity_mean']\n",
    "\n",
    "# number of points to re-sample the edge\n",
    "point_num = 200\n",
    "\n",
    "# proposed size of the hanning window for smoothing\n",
    "# replaced with the 10% of signal length\n",
    "hanning_size = 81\n",
    "\n",
    "# number of layers for radial distributions\n",
    "layer_num = 20\n",
    "\n",
    "# original df columns\n",
    "columns_org = ['label', 'area', 'centroid-0', 'centroid-1', 'bbox-0', 'bbox-1', 'bbox-2', 'bbox-3', 'eccentricity', 'orientation', 'intensity_image', 'image'] #note that image and intensity image are added in this orientation \n",
    "columns_intensity = [f'mean_{x}' for x in channel_names] + ['mean_fibers']\n",
    "\n",
    "# prepare column names to store complex things later\n",
    "columns_to_add = ['actin_detected','actin_angles','membrane_orientation','mem_act_orientation','edge_points','edge_image','edge_points_cell','mem_orientation_edge','plak_smooth','orientation_smooth']\n",
    "# add names of edge signals based on channel names\n",
    "for c in channel_names:\n",
    "    columns_to_add.append(f'edge_signal_{c}')\n",
    "# add names of radial signals based on channel names\n",
    "for c in channel_names:\n",
    "    columns_to_add.append(f'signal_radial_{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_mask.png',\n",
       " '02_mask.png',\n",
       " '04_mask.png',\n",
       " '05_mask.png',\n",
       " '07_mask.png',\n",
       " '16_mask.png',\n",
       " '17_mask.png',\n",
       " '20_mask.png',\n",
       " '24_mask.png',\n",
       " '27_mask.png',\n",
       " '29_mask.png',\n",
       " '30_mask.png',\n",
       " '31_mask.png',\n",
       " '33_mask.png',\n",
       " '36_mask.png',\n",
       " '38_mask.png',\n",
       " '40_mask.png',\n",
       " '41_mask.png',\n",
       " '46_mask.png',\n",
       " '47_mask.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of masks to process\n",
    "\n",
    "file_list = [x for x in os.listdir(mask_dir) if 'png' in x]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for mask_file in file_list:\n",
    "\n",
    "    ####################################################################################################\n",
    "    # open image and mask\n",
    "\n",
    "    # open mask \n",
    "    mask_path = os.path.join(mask_dir,mask_file)\n",
    "    mask = imread_png(mask_path)\n",
    "\n",
    "    # open original image\n",
    "    num = int(mask_file[:2])\n",
    "    im_name = str(num).zfill(2) +'.nd2'\n",
    "    im_path = os.path.join(im_dir,im_name)\n",
    "    im = nd2.imread(im_path)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # read in vertices\n",
    "\n",
    "    pkl_path = os.path.join(vertices_dir,im_name.replace('.nd2','_polygons.pkl'))\n",
    "\n",
    "    with open(pkl_path, 'rb') as f:\n",
    "        vertices_polygons = pickle.load(f)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # actin segmentation\n",
    "\n",
    "    # get actin channel\n",
    "    image_actin = im[:,0,:,:]\n",
    "\n",
    "    # segment actin volume\n",
    "    image_actin_mask = segment_actin_3D(image_actin)\n",
    "\n",
    "    # flatten segmented actin\n",
    "    image_actin_mask_2D = np.max(image_actin_mask,axis=0)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # calculate general properties\n",
    "    im_flat_all_channels = np.max(im,axis=0)\n",
    "    im_flat_all = np.append(im_flat_all_channels,np.expand_dims(image_actin_mask_2D,axis=0),axis=0)\n",
    "    im_flat_all = np.moveaxis(im_flat_all,0,2)\n",
    "\n",
    "    cell_measure = regionprops_table(mask, intensity_image = im_flat_all, properties = properties)\n",
    "    df = pd.DataFrame(cell_measure)\n",
    "\n",
    "    ####################################################################################################\n",
    "    # maintenance of the df\n",
    "    # renaming and adding columns\n",
    "    # adding addtional info\n",
    "    \n",
    "    # renaming columns\n",
    "    df.columns = columns_org + columns_intensity\n",
    "\n",
    "    # adding columns\n",
    "    for c in columns_to_add:\n",
    "        df[c] = None\n",
    "        df[c] = df[c].astype(object)\n",
    "\n",
    "    # adding info to df\n",
    "    df['image_name'] = im_name\n",
    "    \n",
    "    # uncover and add condition\n",
    "    condition = get_condition(num)\n",
    "    df['condition'] = condition\n",
    "\n",
    "    # check that the image contain DAPI\n",
    "    dapi = check_dapi(num)\n",
    "    df['dapi_present'] = dapi\n",
    "\n",
    "    ####################################################################################################\n",
    "    # add vertices to the table\n",
    "    df['vertices'] = vertices_polygons\n",
    "\n",
    "    ####################################################################################################################################\n",
    "    ####################################################################################################################################\n",
    "    ####################################################################################################################################\n",
    "    # add calculations for individual cells\n",
    "\n",
    "    for ind,cell in df.iterrows():\n",
    "\n",
    "        # ACTIN\n",
    "        ####################################################################################################\n",
    "        ####################################################################################################\n",
    "        # calculate actin organization\n",
    "\n",
    "        # calculate dominant actin orientation\n",
    "        im_single_cell_actin = cell.intensity_image[:,:,-1]\n",
    "\n",
    "        actin,actin_angles = find_fibers_orientation_v2(im_single_cell_actin)\n",
    "        \n",
    "        # calculate mean orientation of the fibers\n",
    "        actin_orientation = circmean(actin_angles,low = -np.pi/2, high = np.pi/2)\n",
    "\n",
    "        # calculate spread of orientations\n",
    "        actin_spread = circstd(actin_angles,low = -np.pi/2, high = np.pi/2)\n",
    "\n",
    "        df.at[ind,'actin_detected'] = np.array(actin)\n",
    "        df.at[ind,'actin_angles'] = np.array(actin_angles)\n",
    "        df.loc[ind,'actin_orientation'] = actin_orientation\n",
    "        df.loc[ind,'actin_spread'] = actin_spread\n",
    "\n",
    "        # RADIAL\n",
    "        ####################################################################################################\n",
    "        ####################################################################################################\n",
    "        # calculate radial distributions\n",
    "\n",
    "        # generate distance transform\n",
    "        cell_shape = cell.image\n",
    "        dist = distance_transform_edt(cell_shape)\n",
    "\n",
    "        # digitize distance transform\n",
    "        step = np.max(dist)/layer_num\n",
    "\n",
    "        for n in range(layer_num):\n",
    "\n",
    "            dist[(dist>(n*step)) & (dist<=((n+1)*step))] = n+1\n",
    "\n",
    "        # calculate radial distribution signals\n",
    "        for s,ch_name in enumerate(channel_names):\n",
    "\n",
    "            signal_image = cell.intensity_image[:,:,s]\n",
    "\n",
    "            signal_list = []\n",
    "            for n in range(layer_num):\n",
    "\n",
    "                signal = np.median(signal_image[dist==(n+1)])\n",
    "\n",
    "                signal_list.append(signal)\n",
    "\n",
    "            df.at[ind,f'signal_radial_{ch_name}'] = np.array(signal_list)\n",
    "\n",
    "        # EDGE\n",
    "        ####################################################################################################\n",
    "        ####################################################################################################\n",
    "        # add cell vertices\n",
    "        vertices = (cell.vertices).astype(int)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # calculate membrane orientation\n",
    "        membrane_orientation = orientations_from_vertices(vertices)\n",
    "        df.at[ind,'membrane_orientation'] = membrane_orientation\n",
    "\n",
    "        ####################################################################################################\n",
    "        # recalculate membrane orientation vs actin\n",
    "        orientations = []\n",
    "        for angle_membrane in membrane_orientation:\n",
    "\n",
    "            orientation = calculate_perpendicular_index(actin_orientation,angle_membrane)\n",
    "\n",
    "            orientations.append(orientation)\n",
    "\n",
    "        df.at[ind,'mem_act_orientation'] = np.array(orientations)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # calculate points at the perimeter\n",
    "\n",
    "        # create a polygon from vertices\n",
    "        p = Polygon(cell.vertices)\n",
    "\n",
    "        # gen n points evently distributed at the border\n",
    "        perim = np.array([p.exterior.interpolate(t).xy for t in np.linspace(0,p.length,point_num,False)])[:,:,0]\n",
    "   \n",
    "        df.at[ind,'edge_points'] = np.array(perim)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # recalculate perimeter points in the coordinate system of a cell\n",
    "        perim[:,0] = perim[:,0] - cell['bbox-0']\n",
    "        perim[:,1] = perim[:,1] - cell['bbox-1']\n",
    "\n",
    "        df.at[ind,'edge_points_cell'] = np.array(perim)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # get points distributed at the periphery\n",
    "        df_points = get_internal_points(np.array(perim),line_width=21)\n",
    "\n",
    "        # clean points\n",
    "        df_points['dr'] = [((x>=cell.image.shape[0]) or (y>=cell.image.shape[1])) for x,y in zip(df_points.r,df_points.c)]\n",
    "        df_points.drop(df_points.index[df_points.dr],axis=0,inplace=True)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # calculate edge signals from intensity channels\n",
    "        for i,ch_name in enumerate(channel_names):\n",
    "\n",
    "            # prepare image for signal calculation\n",
    "            im = (cell.intensity_image[:,:,i] * cell.image).astype(float)\n",
    "            im[im==0] = np.NaN\n",
    "\n",
    "            # collect signal values from prepared image\n",
    "            df_points['signal'] = [im[r,c] for r,c in zip(df_points.r,df_points.c)]\n",
    "\n",
    "            # group by order of points\n",
    "            res = df_points.loc[:,['ord','signal']].groupby('ord').mean().reset_index()\n",
    "\n",
    "            # store signal values\n",
    "            c_name = f'edge_signal_{ch_name}'\n",
    "            df.at[ind,c_name] = np.array(res)[:,1]\n",
    "\n",
    "\n",
    "        ####################################################################################################\n",
    "        # calculate edge orientation at edge_points\n",
    "\n",
    "        vertices = cell.vertices.copy()\n",
    "        vertices[:,0] = [np.min([x,im.shape[0]-1]) for x in vertices[:,0] - cell['bbox-0']]\n",
    "        vertices[:,1] = [np.min([x,im.shape[1]-1]) for x in vertices[:,1] - cell['bbox-1']]\n",
    "        vertices = vertices.astype(int)\n",
    "\n",
    "        orientations = np.array(orientations)\n",
    "\n",
    "        # prepare image of edge orientation vs actin\n",
    "        edge_image = create_edge_visual(cell.image.shape,vertices,orientations,line_width=5)\n",
    "        edge_image[edge_image==0] = np.NaN\n",
    "\n",
    "        df.at[ind,'edge_image'] = edge_image\n",
    "\n",
    "        # collect orientaton values from prepared image\n",
    "        df_points['signal'] = [edge_image[r,c] for r,c in zip(df_points.r,df_points.c)]\n",
    "\n",
    "        # group by order of points\n",
    "        res = df_points.loc[:,['ord','signal']].groupby('ord').mean().reset_index()\n",
    "\n",
    "        # store signal values\n",
    "        df.at[ind,'mem_orientation_edge'] = np.array(res)[:,1]\n",
    "\n",
    "        ####################################################################################################\n",
    "        # Calculate smooth signals\n",
    "        # w = np.hanning(hanning_size)\n",
    "\n",
    "        plak_signal = df.loc[ind,'edge_signal_plak']\n",
    "        plak_signal = interpolate_and_fill(plak_signal)\n",
    "\n",
    "        w = np.hanning(int(len(plak_signal)/10))\n",
    "\n",
    "        plak_smooth = np.convolve(w/w.sum(),plak_signal,mode='same')\n",
    "        df.at[ind,'plak_smooth'] = np.array(plak_smooth)\n",
    "\n",
    "        orientation_signal = df.loc[ind,'mem_orientation_edge']\n",
    "        orientation_signal = interpolate_and_fill(orientation_signal)\n",
    "        orientation_smooth = np.convolve(w/w.sum(),orientation_signal,mode='same')\n",
    "        df.at[ind,'orientation_smooth'] = np.array(orientation_smooth)\n",
    "\n",
    "        ####################################################################################################\n",
    "        # calculate Pearson correlation between edge orientation and plakoglobin signal\n",
    "        r, p = stats.pearsonr(orientation_smooth, plak_smooth)\n",
    "        df.loc[ind,'Pearson'] = r\n",
    "\n",
    "    # save data frame\n",
    "    df.to_pickle(os.path.join(save_path,im_name.replace('.nd2','_df_pear.pkl')))\n",
    "    data_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
